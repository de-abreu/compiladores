\documentclass[12pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[brazil]{babel}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{enumitem}

\title{SCC0217 – Linguagens de programação e compiladores \\ Exercícios de revisão sobre gramáticas}
\author{Guilherme de Abreu Barreto, 12543033 \\
Hélio Nogueira Cardoso, 10310227 \\
Theo da Mota dos Santos, 10691331 \\
Laura Fernandes Camargos, 13692334 \\
Sandy da Costa Dutra, 12544570}
\date{\today}

\begin{document}

\maketitle

\section*{Exercícios}

\begin{enumerate}
	\item Crie uma gramática para a linguagem $ww^r$, onde $w$ é uma cadeia não vazia e $w^r$ é o reverso de $w$.
	      
	      \textbf{Solução:}
	      
	      Gramática Formal $G=(V_n,V_t,P,S)$:
	      
	      \begin{itemize}
		      \item Não-terminais ($V_n$): $V_n = \{S\}$
		            
		      \item Terminais ($V_t$): $V_t = \{a, b\}$
		            
		      \item Produções ($P$):
		            \begin{align*}
			            S & \rightarrow aSa \mid bSb \mid aa \mid bb
		            \end{align*}
		            Onde:
		            \begin{itemize}
			            \item $S \rightarrow aSa$ e $S \rightarrow bSb$: geram os casos recursivos
			            \item $S \rightarrow aa$ e $S \rightarrow bb$: casos base para strings mínimas
		            \end{itemize}
		            
		      \item Símbolo Inicial: $S$
	      \end{itemize}
	      
	      \textbf{Características:}
	      \begin{itemize}
		      \item Gera apenas cadeias de comprimento par
		      \item Todas as cadeias geradas são da forma $ww^r$
		      \item O comprimento mínimo é 2 (casos base)
	      \end{itemize}
	      
	      \textbf{Exemplos de derivação:}
	      \begin{itemize}
		      \item Para $w = a$: $ww^r = aa$ \\
		            Derivação: $S \Rightarrow aa$
		            
		      \item Para $w = ab$: $ww^r = abba$ \\
		            Derivação: $S \Rightarrow aSa \Rightarrow abSba \Rightarrow abba$
		            
		      \item Para $w = aab$: $ww^r = aabbaa$ \\
		            Derivação: $S \Rightarrow aSa \Rightarrow aaSaa \Rightarrow aabSbaa \Rightarrow aabbaa$
	      \end{itemize}
	      
	\item Crie uma gramática livre de contexto que represente o conjunto de expressões algébricas envolvendo os identificadores $x$ e $y$ e as operações de adição, subtração, multiplicação e divisão, além dos parênteses.
	      
	      \textbf{Solução:}
	      \begin{align*}
		      E & \rightarrow E + T \mid E - T \mid T \\
		      T & \rightarrow T * F \mid T / F \mid F \\
		      F & \rightarrow (E) \mid x \mid y
	      \end{align*}
	      
	\item Na resposta da questão anterior, existe precedência diferente entre os operadores utilizados? Se sim, fornecer a relação de precedência. Caso não exista precedência diferente, reescrever a gramática de forma que exista uma relação de precedência adequada entre os operadores.
	      
	      \textbf{Solução:} Sim, na gramática que apresentamos na resposta anterior existe precedência entre os operadores, seguindo a hierarquia matemática padrão. A gramática está estruturada para refletir a seguinte ordem de precedência:
	      \begin{itemize}
		      \item Parênteses: ( ) (maior precedência, resolvidos primeiro)
		      \item Multiplicação e Divisão: *, / (associativos à esquerda)
		      \item Adição e Subtração: +, - (associativos à esquerda)
	      \end{itemize}
	      
	      Fizemos isso impondo a precedência através de níveis hierárquicos de não-terminais: F (Fator), T (Termo) e E (Expressão). Caso não houvesse precedência teríamos uma gramática ambígua, por exemplo:
	      
	      \begin{align*}
		      E & \rightarrow E + E \mid E * E \mid (E) \mid x \mid y
	      \end{align*}
	      
	      que permite derivações distintas para \texttt{x + y * x}:
	      \begin{itemize}
		      \item \texttt{(x + y) * x} (incorreta, se esperamos prioridade de *)
		      \item \texttt{x + (y * x)} (correta)
	      \end{itemize}
	      
	\item Prove, via construção de gramáticas, que uma linguagem livre de contexto é fechada sobre a operação de união, concatenação e fechamento.
	      
	      \textbf{Solução:}
	      
	      Em nossas demonstrações iremos assumir um par de linguagens livres de
	      contexto, $L_1$ e $L_2$ com correspondentes gramáticas $G_1$ e $G_2$,
	      a partir das quais serão construídas as novas gramáticas fechadas sob
	      união ($L_1 \cup L_2$), concatenação ($L_1 \cdot L_2$) e fecho
	      ($L_1\*$, também conhecido como \textit{Estrela de Kleene} ou
	      conjunto infinitamente contável).
	      
	      \begin{itemize}
		      \item Seja $G_1$ definido por $G_1 = (V_1, \sum_1, R_1, S_1)$,
		            sendo:
		            \begin{itemize}
			            \item $V_1$ um conjunto de símbolos não terminais;
			            \item $\sum_1$ um conjunto de símbolos terminais;
			            \item $R_1$ um conjunto de regras de geração;
			            \item $S_1$ o símbolo inicial.
		            \end{itemize}
		      \item e $G_2$ definido de maneira similar.
	      \end{itemize}
	      
	      Assumimos, sem perda de generalidade, que $V_1$ e $V_2$ são
	      \textit{disjuntos entre si}. Isto pois, doutra forma, podemos
	      simplesmente renomear os símbolos não terminais em uma destas
	      gramáticas para satisfazer esta condição.
	      
	      \textbf{1. Fechamento sob união ($L_1 \cup L_2$)}
	      
	      Seja uma dada gramática $G_{uniao} = (V_{uniao}, \sum_{uniao},
		      R_{uniao}, S_{uniao}$ definida tal que:
	      
	      \begin{itemize}
		      \item $V_{uniao} = V_1 \cup V_2 \cup \{S_{uniao}\}$;
		      \item $\sum_{uniao} = \sum_1 \cup \sum_2$;
		      \item $R_{uniao} = R_1 \cup R_2 \cup \{S_{uniao} \rightarrow S_1
			            \mid S_2\}$;
		      \item $S_{uniao}$ é o novo símbolo inicial
	      \end{itemize}
	      
	      Temos que $G_{uniao}$ é a união das gramáticas $G_1$ e $G_2$ e
	      constitui-se enquanto gramática da linguagem $L_{uniao}$
	      
	      \textbf{Prova:}
	      
	      $L_{uniao}$ é equivalente a $L_1 \cup L_2$ \textit{se, e somente se}
	      toda palavra $w$ presente em $L_1$ ou $L_2$ está presente em
	      $L_{uniao}$.
	      
	      \begin{itemize}
		      \item \textbf{Prova direta:}
		            \begin{itemize}
			            \item Se a palavra $w$ estiver em $L_1$: Então existe uma
			                  derivação $S_1 \rightarrow \dots \rightarrow w$ em
			                  $G_1$. Tido que $R_1$ é subconjunto de $R_{uniao}$ e
			                  $S_{uniao} \rightarrow S_1$ está em $R_{uniao}$,
			                  possuímos uma derivação $S_{uniao} \rightarrow S_1
				                  \rightarrow \dots \rightarrow w$ em $G_{uniao}$. Logo,
			                  $w$ está em $L_{uniao}$;
			            \item De maneira análoga, se $w$ estiver em $L_2$, também
			                  estará em $L_{uniao}$. $\square$
		            \end{itemize}
		      \item \textbf{Prova da recíproca:}
		            \begin{itemize}
			            \item Se a palavra $w$ está em $L_{uniao}$: então existe
			                  uma derivação $S_{uniao} \rightarrow \dots \rightarrow
				                  w$ em $G_{uniao}$. Tido que a derivação imediata de
			                  $S_{uniao}$ é $S_{uniao} \rightarrow S_1 \mid S_2$, se
			                  $w$ estiver em $S_1$, o restante das derivações
			                  seguem regras descritas em $R_1$ e portanto $w$ tem
			                  de estar em $L_1$; Doutra forma está em $S_2$ e de
			                  maneira análoga estará em $L_2$. $\blacksquare$
		            \end{itemize}
	      \end{itemize}
	      
	      \textbf{2. Fechamento sobre concatenação ($L_1 \cdot L_2$):}
	      
	      Seja uma dada gramática $G_{concat} = (V_{concat}, \sum_{concat},
		      R_{concat}, S_{concat}$ definida tal que:
	      
	      \begin{itemize}
		      \item $V_{concat} = V_1 \cup V_2 \cup \{S_{concat}\}$;
		      \item $\sum_{concat} = \sum_1 \cup \sum_2$;
		      \item $R_{concat} = R_1 \cup R_2 \cup \{S_{concat} \rightarrow
			            S_1S_2\}$;
		      \item $S_{concat}$ é o novo símbolo inicial
	      \end{itemize}
	      
	      Temos que $G_{concat}$ é a concatenação das gramáticas $G_1$ e $G_2$ e
	      constitui-se enquanto gramática da linguagem $L_{concat}$
	      
	      \begin{itemize}
		      \item \textbf{Prova direta:} se a palavra $w$ está em $L_1 \cdot
			            L_2$, então $w = x y$, onde $x$ encontra-se em $L_1$ e $y$
		            encontra-se em $L_2$. Isto é, existem derivações tais que $S_1
			            \rightarrow \dots \rightarrow x$ em $G_1$ e $S_2
			            \rightarrow \dots \rightarrow y$ em $G_2$. Em $G_{concat}$
		            tem-se que $S_{concat} \rightarrow S_1S_2 \rightarrow xS_2
			            \rightarrow xy = w$. Logo $w$ está em
		            $L_{concat}$. $\square$
		            
		      \item \text{Prova da recíproca:} se a palavra $w$ está em
		            $L_{concat}$ há uma derivação tal que $S_{concat}
			            \rightarrow w$ Como $S_{concat} \rightarrow S_1S_2$ e
		            $S_1$ segue as regras de derivação estabelecidas em
		            $R_1$, tem-se que $w = xS_2$. O análogo se segue para
		            $S_2$, $R_2$ e $y$. Portanto $w = x y$ e $w$ está em
		            $L_1 \cdot L_2$. $\blacksquare$
	      \end{itemize}
	      
	      \textbf{Fechamento sob estrela de Kleene ($L^*$):}
	      
	      Seja uma dada gramática $G^* = (V^*, \sum^*, R^*, S^*$ definida tal
	      que:
	      
	      \begin{itemize}
		      \item $V^* = V_1 \cup \{S^*\}$;
		      \item $\sum^* = \sum_1$;
		      \item $R^* = R_1 \cup \{S^* \rightarrow S_1S^* \mid \lambda\}$;
		      \item $S^*$ é o novo símbolo inicial
	      \end{itemize}
	      
	      Temos que $G\*$ é a concatenação das gramáticas $G_1$ uma ou mais
	      vezes e constitui-se enquanto gramática da linguagem $L\*$
	      
	      
	      \textbf{Prova}
	      
	      Se a palavra $w$ está em $L^*$, então ou $w$ é $\lambda$, ou então uma
	      concatenação de um ou mais caracteres terminais de $L_1$ (isto é, $w =
		      x_1x_2 \dots x_n$, onde cada $x_i$ está em $L_1$). Se $w = \lambda$,
	      temos que $S^* \rightarrow \lambda$ é uma derivação. Senão,
	      podemos derivar $w$ infinitamente pelo uso repetido da regra $S\*
		      \rightarrow S_1S^*$, gerando $S_1S_1 \dots S_1 S^*$, com
	      cada $S_1$ leavando a um $x_i$ correspondente e $S^*
		      \rightarrow \lambda\ \blacksquare$.
	      
	\item Sobre gramáticas em geral, considere as seguintes questões:
	      \begin{enumerate}[label=\alph*)]
		      \item Forneça a definição de gramática.
		            
		            \textbf{Solução:} É uma maneira de listar de forma finita uma linguagem (finita ou infinita). Uma definição formal de gramática é uma tupla $G=(V_n,V_t,P,S)$: onde:
		            \begin{itemize}
			            \item $V_n$: conjunto de símbolos não terminais da gramática
			            \item $V_t$: conjunto de símbolos terminais da gramática, os quais constituem as sentenças da linguagem, com $V_n \cap V_t = \emptyset$
			            \item $P$: regra de produção, responsáveis por produzir as sentenças da linguagem
			            \item $S$: símbolo inicial da gramática, por onde se começa a derivação de sentenças
		            \end{itemize}
		            
		      \item Baseado em a), forneça uma gramática para a linguagem $0^n1^{2n}0^m$, para $n$ e $m$ estritamente positivos.
		            
		            \textbf{Solução:}
		            
		            Gramática Formal $G=(V_n,V_t,P,S)$:
		            
		            \begin{itemize}
			            \item Não-terminais ($V_n$): $V_n = \{S, A, B\}$
			                  \begin{itemize}
				                  \item $S$: Símbolo inicial
				                  \item $A$: Gera o padrão $0^n1^{2n}$
				                  \item $B$: Gera o padrão $0^m$
			                  \end{itemize}
			                  
			            \item Terminais ($V_t$): $V_t = \{0, 1\}$
			                  
			            \item Produções ($P$):
			                  \begin{align*}
				                  S & \rightarrow AB \quad \text{(Combina as partes fixas)}                    \\
				                  A & \rightarrow 0A11 \mid 011 \quad \text{(Gera $0^n1^{2n}$ com $n \geq 1$)} \\
				                  B & \rightarrow 0B \mid 0 \quad \text{(Gera $0^m$ com $m \geq 1$)}
			                  \end{align*}
			                  
			            \item Símbolo Inicial: $S$
		            \end{itemize}
		            
		            
		      \item Classifique sua gramática na hierarquia de Chomsky.
		            
		            \textbf{Solução:} A gramática é livre de contexto (Tipo 2), pois todas as produções são da forma $A \rightarrow \alpha$ com $A$ um não-terminal e $\alpha$ uma cadeia de terminais e não-terminais. Sendo assim, no lado esquerdo da regra há apenas um símbolo não-terminal.
	      \end{enumerate}
	      
	\item Escreva uma gramática que represente a linguagem $0^n1^m$, para:
	      \begin{enumerate}[label=\alph*)]
		      \item $n < m$
		            
		            \textbf{Solução:}
		            
		            A linguagem $L = \{0^n 1^m \ | \ n < m \}$ pode ser gerada pela seguinte gramática:
		            \begin{align*}
			            S & \rightarrow AB         \\
			            A & \rightarrow 0A1 \mid B \\
			            B & \rightarrow 1B \mid 1
		            \end{align*}
		            
		            A segunda regra ($A \rightarrow 0A1 \mid B$) garante que cada 0 adicionado à esquerda é balanceado com um 1 à direita, ao mesmo tempo, permite que se "escape" para a terceira regra, que coloca mais indefinidos 1 (pelo menos 1), o que garante que a quantidade de 1 será maior que a de 0.
		            
		      \item $n > m$
		            
		            \textbf{Solução:}
		            
		            Para a linguagem $L = \{0^n 1^m \ | \ n > m \}$ a gramática é semelhante:
		            \begin{align*}
			            S & \rightarrow AB         \\
			            B & \rightarrow 0B1 \mid A \\
			            A & \rightarrow 0A \mid 0
		            \end{align*}
		            
		            A segunda regra balanceia os 0s e 1s, até que se "escape" para a regra 3, a qual coloca 0s de maneira indefinida (pelo menos 1).
	      \end{enumerate}
	      
	\item Qual gramática é utilizada para descrever linguagens de programação. Justifique sua resposta.
	      
	      \textbf{Solução:}
	      Cada fase da análise em compiladores (léxica, sintática e semântica) lida com diferentes aspectos da linguagem de programação e se utiliza de diferentes formalismos. A análise léxica, que identifica palavras-chave e identificadores, é feita com Linguagens Regulares, já a sintática, que verifica a hierarquia do código, é feita com Linguagens Livres de Contexto. Por fim, a análise semântica, que avalia o significado das expressões, é feita com Linguagens Sensíveis ao Contexto.
	      
	\item Dada uma linguagem livre de contexto $L$, é possível dizer que $L - \{\lambda\}$ também é livre de contexto?
	      
	      \textbf{Solução:} Sim, a classe das linguagens livres de contexto é fechada sob a operação de diferença com um conjunto finito. Portanto, se $L$ é livre de contexto, então $L - \{\lambda\}$ também é livre de contexto.
	      
	      \textbf{Provando:} Seja $G = (V_n, V_t, P, S)$ uma GLC que gera $L$. Podemos construir uma gramática $G'$ para $L - \{\lambda\}$ da seguinte forma:
	      
	      \begin{enumerate}
		      \item \textbf{Caso 1:} Se $\lambda \notin L$, então $G' = G$ (nada precisa ser feito)
		            
		      \item \textbf{Caso 2:} Se $\lambda \in L$, construímos $G' = (V_n \cup \{S'\}, V_t, P', S')$ onde:
		            \begin{itemize}
			            \item $S'$ é um novo símbolo inicial ($S' \notin V_n$)
			            \item $P' = P \cup \{S' \rightarrow \alpha \mid S \rightarrow \alpha \in P \text{ e } \alpha \neq \lambda\}$
			            \item Removemos todas as produções que derivam diretamente $\lambda$ do novo símbolo inicial
		            \end{itemize}
	      \end{enumerate}
\end{enumerate}

\end{document}
